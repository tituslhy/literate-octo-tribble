{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import warnings\n",
    "import nest_asyncio\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "nest_asyncio.apply()\n",
    "_ = load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "llm = OpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Human in the loop two ways"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. The `HumanResponseEvent` approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.workflow import (\n",
    "    Workflow,\n",
    "    step,\n",
    "    Event,\n",
    "    Context,\n",
    "    StartEvent,\n",
    "    StopEvent\n",
    ")\n",
    "from llama_index.core.workflow.events import InputRequiredEvent, HumanResponseEvent\n",
    "from llama_index.core.chat_engine import SimpleChatEngine"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This workflow is as simple as it gets! We ask for the username because we only allow a specific user to invoke the workflow. So if the user is not `Titus`, we just simply won't run it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnswerEvent(Event):\n",
    "    query: str\n",
    "\n",
    "class AskLLM(Workflow):\n",
    "    def __init__(self, llm = llm,  *args, **kwargs):\n",
    "        self.user = None\n",
    "        self.approved_users = [\"Titus\"]\n",
    "        self.engine = SimpleChatEngine.from_defaults(llm=llm)\n",
    "        super().__init__(*args, **kwargs)\n",
    "    \n",
    "    @step(pass_context=True)\n",
    "    async def start(self, ctx: Context, ev: StartEvent) -> InputRequiredEvent | AnswerEvent:\n",
    "        if self.user is None:\n",
    "            print(\"Unidentified user. Verifying credentials...\\n\\n\")\n",
    "            await ctx.set(\"query\", ev.query)\n",
    "            return InputRequiredEvent(prefix=\"Please identify yourself: \")\n",
    "        return AnswerEvent(query=ev.query)\n",
    "\n",
    "    @step(pass_context=True)\n",
    "    async def authenticate(self, ctx: Context, ev: HumanResponseEvent) -> AnswerEvent | StopEvent:\n",
    "        user = ev.response\n",
    "        if user in self.approved_users:\n",
    "            self.user = user\n",
    "            query = await ctx.get(\"query\")\n",
    "            return AnswerEvent(query=str(query))\n",
    "        return StopEvent(result = \"Unauthorized user. Please acquire authorization credentials from administrators.\")\n",
    "    \n",
    "    @step\n",
    "    async def answer(self, ev: AnswerEvent) -> StopEvent:\n",
    "        response = self.engine.chat(ev.query)\n",
    "        return StopEvent(result=str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.utils.workflow import draw_all_possible_flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_all_possible_flows(AskLLM, filename=\"AskLLM.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unidentified user. Verifying credentials...\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "app1 = AskLLM()\n",
    "\n",
    "handler1 = app1.run(query=\"What is OpenAI?\")\n",
    "\n",
    "## Use a for-loop to handle the `HumanResponseEvent`\n",
    "async for event in handler1.stream_events():\n",
    "    if isinstance(event, InputRequiredEvent):\n",
    "        response = input(event.prefix)\n",
    "        handler1.ctx.send_event(HumanResponseEvent(response=response))\n",
    "\n",
    "final_result = await handler1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "OpenAI is an artificial intelligence research organization that aims to develop and promote friendly AI for the benefit of humanity. Founded in December 2015, OpenAI conducts research in various areas of AI, including machine learning, natural language processing, robotics, and more. The organization is known for creating advanced AI models, such as the GPT (Generative Pre-trained Transformer) series, which includes models like ChatGPT.\n",
       "\n",
       "OpenAI's mission is to ensure that artificial general intelligence (AGI) is aligned with human values and can be used safely and responsibly. The organization emphasizes transparency, collaboration, and ethical considerations in AI development. OpenAI also engages with the broader community through partnerships, publications, and open-source projects to foster a responsible approach to AI technology."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(final_result))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. The `StopEvent` approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AuthEvent(Event):\n",
    "    user: str\n",
    "\n",
    "class AskLLM_2(Workflow):\n",
    "    def __init__(self, llm = llm,  *args, **kwargs):\n",
    "        self.user = None\n",
    "        self.approved_users = [\"Titus\"]\n",
    "        self.engine = SimpleChatEngine.from_defaults(llm=llm)\n",
    "        super().__init__(*args, **kwargs)\n",
    "    \n",
    "    @step(pass_context=True)\n",
    "    async def start(self, ctx: Context, ev: StartEvent) -> StopEvent | AuthEvent:\n",
    "        if ev.user is None:\n",
    "            return StopEvent(\"Please furnish your user credentials.\")\n",
    "        await ctx.set(\"query\", ev.query)\n",
    "        return AuthEvent(user=ev.user)\n",
    "\n",
    "    @step(pass_context=True)\n",
    "    async def authenticate(self, ctx: Context, ev: AuthEvent) -> AnswerEvent | StopEvent:\n",
    "        user = ev.user\n",
    "        if user in self.approved_users:\n",
    "            self.user = user\n",
    "            query = await ctx.get(\"query\")\n",
    "            return AnswerEvent(query=str(query))\n",
    "        return StopEvent(result = \"Unauthorized user. Please acquire authorization credentials from administrators.\")\n",
    "    \n",
    "    @step\n",
    "    async def answer(self, ev: AnswerEvent) -> StopEvent:\n",
    "        response = self.engine.chat(ev.query)\n",
    "        return StopEvent(result=str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AskLLM_all.html\n"
     ]
    }
   ],
   "source": [
    "draw_all_possible_flows(AskLLM_2, filename=\"AskLLM_2.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Please furnish your user credentials."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "app2 = AskLLM_2()\n",
    "\n",
    "response = await app2.run(query=\"What is a Large Language Model?\", user=None)\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Unauthorized user. Please acquire authorization credentials from administrators."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = await app2.run(query=\"What is a Large Language Model?\", user=\"Bob\")\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = await app2.run(query=\"What is a Large Language Model?\", user=\"Titus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "A Large Language Model (LLM) is a type of artificial intelligence model designed to understand, generate, and manipulate human language. These models are built using deep learning techniques, particularly neural networks, and are trained on vast amounts of text data from diverse sources, such as books, articles, websites, and more.\n",
       "\n",
       "Key characteristics of LLMs include:\n",
       "\n",
       "1. **Scale**: LLMs are characterized by their large number of parameters, often in the billions or even trillions. This scale allows them to capture complex patterns and nuances in language.\n",
       "\n",
       "2. **Training**: They are trained using unsupervised or semi-supervised learning methods, where the model learns to predict the next word in a sentence given the previous words. This process helps the model understand grammar, context, and even some level of reasoning.\n",
       "\n",
       "3. **Versatility**: LLMs can perform a wide range of language-related tasks, including text generation, translation, summarization, question answering, and more, often with little to no task-specific training.\n",
       "\n",
       "4. **Contextual Understanding**: They can generate coherent and contextually relevant text based on the input they receive, making them useful for applications like chatbots, content creation, and interactive storytelling.\n",
       "\n",
       "5. **Limitations**: Despite their capabilities, LLMs can produce incorrect or nonsensical answers, may reflect biases present in the training data, and lack true understanding or consciousness.\n",
       "\n",
       "Examples of LLMs include OpenAI's GPT-3 and GPT-4, Google's BERT and T5, and Meta's LLaMA. These models have significantly advanced the field of natural language processing (NLP) and continue to evolve with ongoing research and development."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(response))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Deploying Workflows\n",
    "LlamaIndex has many interesting Workflow implementations of research papers! Here's one of my favorites: the `Self-Discovery Workflow`, a \"general framework for LLMs to self-discover the task-intrinsic reasoning structures to tackle complex reasoning problems that are challenging for typical prompting methods\".\n",
    "\n",
    "There are two stages for any given task:\n",
    "\n",
    "STAGE-1:\n",
    "\n",
    "a. SELECT: Selects subset of reasoning Modules.\n",
    "\n",
    "b. ADAPT: Adapts selected reasoning modules to the task.\n",
    "\n",
    "c. IMPLEMENT: It gives reasoning structure for the task.\n",
    "\n",
    "STAGE-2: Uses the generated reasoning structure for the task to generate an answer.\n",
    "\n",
    "> Reference: [Paper](https://arxiv.org/abs/2402.03620)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.prompts import PromptTemplate\n",
    "\n",
    "_REASONING_MODULES = [\n",
    "    \"1. How could I devise an experiment to help solve that problem?\",\n",
    "    \"2. Make a list of ideas for solving this problem, and apply them one by one to the problem to see if any progress can be made.\",\n",
    "    \"3. How could I measure progress on this problem?\",\n",
    "    \"4. How can I simplify the problem so that it is easier to solve?\",\n",
    "    \"5. What are the key assumptions underlying this problem?\",\n",
    "    \"6. What are the potential risks and drawbacks of each solution?\",\n",
    "    \"7. What are the alternative perspectives or viewpoints on this problem?\",\n",
    "    \"8. What are the long-term implications of this problem and its solutions?\",\n",
    "    \"9. How can I break down this problem into smaller, more manageable parts?\",\n",
    "    \"10. Critical Thinking: This style involves analyzing the problem from different perspectives, questioning assumptions, and evaluating the evidence or information available. It focuses on logical reasoning, evidence-based decision-making, and identifying potential biases or flaws in thinking.\",\n",
    "    \"11. Try creative thinking, generate innovative and out-of-the-box ideas to solve the problem. Explore unconventional solutions, thinking beyond traditional boundaries, and encouraging imagination and originality.\",\n",
    "    \"12. Seek input and collaboration from others to solve the problem. Emphasize teamwork, open communication, and leveraging the diverse perspectives and expertise of a group to come up with effective solutions.\",\n",
    "    \"13. Use systems thinking: Consider the problem as part of a larger system and understanding the interconnectedness of various elements. Focuses on identifying the underlying causes, feedback loops, and interdependencies that influence the problem, and developing holistic solutions that address the system as a whole.\",\n",
    "    \"14. Use Risk Analysis: Evaluate potential risks, uncertainties, and tradeoffs associated with different solutions or approaches to a problem. Emphasize assessing the potential consequences and likelihood of success or failure, and making informed decisions based on a balanced analysis of risks and benefits.\",\n",
    "    \"15. Use Reflective Thinking: Step back from the problem, take the time for introspection and self-reflection. Examine personal biases, assumptions, and mental models that may influence problem-solving, and being open to learning from past experiences to improve future approaches.\",\n",
    "    \"16. What is the core issue or problem that needs to be addressed?\",\n",
    "    \"17. What are the underlying causes or factors contributing to the problem?\",\n",
    "    \"18. Are there any potential solutions or strategies that have been tried before? If yes, what were the outcomes and lessons learned?\",\n",
    "    \"19. What are the potential obstacles or challenges that might arise in solving this problem?\",\n",
    "    \"20. Are there any relevant data or information that can provide insights into the problem? If yes, what data sources are available, and how can they be analyzed?\",\n",
    "    \"21. Are there any stakeholders or individuals who are directly affected by the problem? What are their perspectives and needs?\",\n",
    "    \"22. What resources (financial, human, technological, etc.) are needed to tackle the problem effectively?\",\n",
    "    \"23. How can progress or success in solving the problem be measured or evaluated?\",\n",
    "    \"24. What indicators or metrics can be used?\",\n",
    "    \"25. Is the problem a technical or practical one that requires a specific expertise or skill set? Or is it more of a conceptual or theoretical problem?\",\n",
    "    \"26. Does the problem involve a physical constraint, such as limited resources, infrastructure, or space?\",\n",
    "    \"27. Is the problem related to human behavior, such as a social, cultural, or psychological issue?\",\n",
    "    \"28. Does the problem involve decision-making or planning, where choices need to be made under uncertainty or with competing objectives?\",\n",
    "    \"29. Is the problem an analytical one that requires data analysis, modeling, or optimization techniques?\",\n",
    "    \"30. Is the problem a design challenge that requires creative solutions and innovation?\",\n",
    "    \"31. Does the problem require addressing systemic or structural issues rather than just individual instances?\",\n",
    "    \"32. Is the problem time-sensitive or urgent, requiring immediate attention and action?\",\n",
    "    \"33. What kinds of solution typically are produced for this kind of problem specification?\",\n",
    "    \"34. Given the problem specification and the current best solution, have a guess about other possible solutions.\"\n",
    "    \"35. Let’s imagine the current best solution is totally wrong, what other ways are there to think about the problem specification?\"\n",
    "    \"36. What is the best way to modify this current best solution, given what you know about these kinds of problem specification?\"\n",
    "    \"37. Ignoring the current best solution, create an entirely new solution to the problem.\"\n",
    "    \"38. Let’s think step by step .\"\n",
    "    \"39. Let’s make a step by step plan and implement it with good notation and explanation.\",\n",
    "]\n",
    "\n",
    "_REASONING_MODULES = \"\\n\".join(_REASONING_MODULES)\n",
    "\n",
    "SELECT_PRMOPT_TEMPLATE = PromptTemplate(\n",
    "    \"Given the task: {task}, which of the following reasoning modules are relevant? Do not elaborate on why.\\n\\n {reasoning_modules}\"\n",
    ")\n",
    "\n",
    "ADAPT_PROMPT_TEMPLATE = PromptTemplate(\n",
    "    \"Without working out the full solution, adapt the following reasoning modules to be specific to our task:\\n{selected_modules}\\n\\nOur task:\\n{task}\"\n",
    ")\n",
    "\n",
    "IMPLEMENT_PROMPT_TEMPLATE = PromptTemplate(\n",
    "    \"Without working out the full solution, create an actionable reasoning structure for the task using these adapted reasoning modules:\\n{adapted_modules}\\n\\nTask Description:\\n{task}\"\n",
    ")\n",
    "\n",
    "REASONING_PROMPT_TEMPLATE = PromptTemplate(\n",
    "    \"Using the following reasoning structure: {reasoning_structure}\\n\\nSolve this task, providing your final answer: {task}\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.llms import LLM\n",
    "\n",
    "class JudgeEvent(Event):\n",
    "    task: str\n",
    "    llm: LLM\n",
    "\n",
    "class SetupEvent(Event):\n",
    "    task: str\n",
    "\n",
    "class GetModulesEvent(Event):\n",
    "    \"\"\"Event to get modules.\"\"\"\n",
    "\n",
    "    task: str\n",
    "    modules: str\n",
    "\n",
    "\n",
    "class RefineModulesEvent(Event):\n",
    "    \"\"\"Event to refine modules.\"\"\"\n",
    "\n",
    "    task: str\n",
    "    refined_modules: str\n",
    "\n",
    "\n",
    "class ReasoningStructureEvent(Event):\n",
    "    \"\"\"Event to create reasoning structure.\"\"\"\n",
    "\n",
    "    task: str\n",
    "    reasoning_structure: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.llms import ChatMessage\n",
    "from llama_index.core.memory import ChatMemoryBuffer\n",
    "from typing import List\n",
    "import json\n",
    "\n",
    "class SelfDiscoverWorkflow(Workflow):\n",
    "    def __init__(\n",
    "        self,\n",
    "        llm: LLM = llm,\n",
    "        chat_history: List[ChatMessage] = [],\n",
    "        *args,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.agent = SimpleChatEngine.from_defaults(llm=llm)\n",
    "        self.chat_history = chat_history\n",
    "    \n",
    "    def process_chat_history(self):\n",
    "        return [message.dict() for message in self.chat_history]\n",
    "    \n",
    "    @step\n",
    "    async def judge_query(self, ctx: Context, ev: StartEvent) -> StopEvent | SetupEvent:\n",
    "        \"\"\"Event to judge whether a query is well-written and to seek\n",
    "        clarification if the query is not well-written\"\"\"\n",
    "        \n",
    "        self.chat_history.append(ChatMessage(**{\"role\": \"user\", \"content\": ev.task}))\n",
    "        \n",
    "        response = await self.agent.achat(\n",
    "            f\"\"\"\n",
    "            Given a user query, determine if this is likely to yield good results from a RAG system as-is. If it's good, return 'good', if it's bad, return 'bad', if \n",
    "            it's not a question (for e.g. \"Hi!\", \"Thanks!\"), return \"not a question\".\n",
    "            Good queries use a lot of relevant keywords and are detailed. Bad queries are vague or ambiguous.\n",
    "\n",
    "            Here is the query: {ev.task}\n",
    "            \"\"\"\n",
    "        )\n",
    "        print(\"\\n\\nJudge Query response: \"+ str(response) + \"\\n\\n\")\n",
    "        if response == \"bad\":\n",
    "            final_response = await self.agent.achat(\n",
    "                f\"\"\"\n",
    "                The user has given a poor query. Seek for clarification from the user.\n",
    "                \n",
    "                Here's the user's query: {ev.task}\n",
    "                \"\"\",\n",
    "                chat_history = self.chat_history\n",
    "            )   \n",
    "            self.chat_history.append(ChatMessage**{\"role\": \"assistant\", \"content\": str(final_response)})\n",
    "            return StopEvent(str(final_response)) \n",
    "        \n",
    "        elif response == \"not a question\":\n",
    "            final_response = await self.agent.achat(\n",
    "                f\"\"\"\n",
    "                Here's the user's remark or greeting: {ev.task}\n",
    "                \n",
    "                Respond to the user politely.\n",
    "                \"\"\",\n",
    "                chat_history = self.chat_history\n",
    "            )   \n",
    "            self.chat_history.append(ChatMessage(**{\"role\": \"assistant\", \"content\": str(final_response)}))\n",
    "            return StopEvent(str(final_response)) \n",
    "        \n",
    "        return SetupEvent(task=ev.task)\n",
    "\n",
    "    @step\n",
    "    async def get_modules(\n",
    "        self, ctx: Context, ev: SetupEvent\n",
    "    ) -> GetModulesEvent:\n",
    "        \"\"\"Get modules step.\"\"\"\n",
    "        task = ev.get(\"task\")\n",
    "        \n",
    "        # format prompt and get result from LLM\n",
    "        prompt = SELECT_PRMOPT_TEMPLATE.format(\n",
    "            task=task, reasoning_modules=_REASONING_MODULES\n",
    "        )\n",
    "        result = await self.agent.achat(prompt, chat_history = self.chat_history)\n",
    "        print(\"\\n\\nModules selected: \" + str(result) + \"\\n\\n\")\n",
    "        self.chat_history.append(ChatMessage(**{\"role\": \"assistant\", \"content\": str(result)}))\n",
    "        return GetModulesEvent(task=str(task), modules=str(result))\n",
    "\n",
    "    @step\n",
    "    async def refine_modules(\n",
    "        self, ctx: Context, ev: GetModulesEvent\n",
    "    ) -> RefineModulesEvent:\n",
    "        \"\"\"Refine modules step.\"\"\"\n",
    "        task = ev.task\n",
    "        modules = ev.modules\n",
    "        \n",
    "        # format prompt and get result\n",
    "        prompt = ADAPT_PROMPT_TEMPLATE.format(\n",
    "            task=task, selected_modules=modules\n",
    "        )\n",
    "        result = await self.agent.achat(prompt, chat_history = self.chat_history)\n",
    "        print(\"\\n\\nRefined modules: \" + str(result) + \"\\n\\n\")\n",
    "        self.chat_history.append(ChatMessage(**{\"role\": \"assistant\", \"content\": str(result)}))\n",
    "        return RefineModulesEvent(task=task, refined_modules=str(result))\n",
    "\n",
    "    @step\n",
    "    async def create_reasoning_structure(\n",
    "        self, ctx: Context, ev: RefineModulesEvent\n",
    "    ) -> ReasoningStructureEvent:\n",
    "        \"\"\"Create reasoning structures step.\"\"\"\n",
    "        task = ev.task\n",
    "        refined_modules = ev.refined_modules\n",
    "\n",
    "        # format prompt, get result\n",
    "        prompt = IMPLEMENT_PROMPT_TEMPLATE.format(\n",
    "            task=task, adapted_modules=refined_modules\n",
    "        )\n",
    "        result = await self.agent.achat(prompt, chat_history = self.chat_history)\n",
    "        print(\"\\n\\nImplementation results: \" + str(result) + \"\\n\\n\")\n",
    "        self.chat_history.append(ChatMessage(**{\"role\": \"assistant\", \"content\": str(result)}))\n",
    "\n",
    "        return ReasoningStructureEvent(\n",
    "            task=task, reasoning_structure=str(result)\n",
    "        )\n",
    "\n",
    "    @step\n",
    "    async def get_final_result(\n",
    "        self, ctx: Context, ev: ReasoningStructureEvent\n",
    "    ) -> StopEvent:\n",
    "        \"\"\"Gets final result from reasoning structure event.\"\"\"\n",
    "        task = ev.task\n",
    "        reasoning_structure = ev.reasoning_structure\n",
    "\n",
    "        # format prompt, get res\n",
    "        prompt = REASONING_PROMPT_TEMPLATE.format(\n",
    "            task=task, reasoning_structure=reasoning_structure\n",
    "        )\n",
    "        result = await self.agent.achat(prompt, chat_history = self.chat_history)\n",
    "        print(\"\\n\\nReasoning: \" + str(result) + \"\\n\\n\")\n",
    "        self.chat_history.append(ChatMessage(**{\"role\": \"assistant\", \"content\": str(result)}))\n",
    "\n",
    "        return StopEvent(\n",
    "            result=str(result) + \" ||History||: \" + json.dumps(self.process_chat_history())\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_all_possible_flows(SelfDiscoverWorkflow, filename=\"SelfDiscover.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = SelfDiscoverWorkflow(timeout=300, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running step judge_query\n",
      "\n",
      "\n",
      "Judge Query response: good\n",
      "\n",
      "\n",
      "Step judge_query produced event SetupEvent\n",
      "Running step get_modules\n",
      "\n",
      "\n",
      "Modules selected: The relevant reasoning modules for this task are:\n",
      "\n",
      "1. How could I devise an experiment to help solve that problem?\n",
      "4. How can I simplify the problem so that it is easier to solve?\n",
      "9. How can I break down this problem into smaller, more manageable parts?\n",
      "10. Critical Thinking: This style involves analyzing the problem from different perspectives, questioning assumptions, and evaluating the evidence or information available.\n",
      "38. Let’s think step by step.\n",
      "39. Let’s make a step by step plan and implement it with good notation and explanation.\n",
      "\n",
      "\n",
      "Step get_modules produced event GetModulesEvent\n",
      "Running step refine_modules\n",
      "\n",
      "\n",
      "Refined modules: Here are the adapted reasoning modules specific to our task:\n",
      "\n",
      "1. **How could I devise an experiment to help solve that problem?**  \n",
      "   Consider creating a visual representation (like a chart or diagram) to track the changes in the number of oranges and apples Michael has at each step of the problem.\n",
      "\n",
      "4. **How can I simplify the problem so that it is easier to solve?**  \n",
      "   Focus on one type of fruit at a time (first calculate the oranges, then the apples) to avoid confusion and streamline the calculations.\n",
      "\n",
      "9. **How can I break down this problem into smaller, more manageable parts?**  \n",
      "   Identify each transaction or event separately: (1) initial count of oranges, (2) giving to brother, (3) trading for apples, (4) discarding spoiled oranges, (5) buying more oranges and apples, (6) giving apples to a friend.\n",
      "\n",
      "10. **Critical Thinking:**  \n",
      "   Analyze the problem by questioning the accuracy of each transaction and ensuring that all steps are accounted for without any assumptions about the initial counts or transactions.\n",
      "\n",
      "38. **Let’s think step by step.**  \n",
      "   Outline each action Michael takes in chronological order, noting how each action affects his total count of oranges and apples.\n",
      "\n",
      "39. **Let’s make a step by step plan and implement it with good notation and explanation.**  \n",
      "   Create a clear list of steps with corresponding calculations for each action, using notation to represent the number of oranges and apples at each stage (e.g., O = oranges, A = apples).\n",
      "\n",
      "\n",
      "Step refine_modules produced event RefineModulesEvent\n",
      "Running step create_reasoning_structure\n",
      "\n",
      "\n",
      "Implementation results: Here’s an actionable reasoning structure for the task using the adapted reasoning modules:\n",
      "\n",
      "### Actionable Reasoning Structure\n",
      "\n",
      "1. **Visual Representation**  \n",
      "   - Create a chart or diagram to visually track the number of oranges and apples at each step. Label the axes (e.g., \"Number of Oranges\" and \"Number of Apples\") and prepare to fill in values as calculations are made.\n",
      "\n",
      "2. **Simplification of the Problem**  \n",
      "   - Decide to calculate the total number of oranges first, followed by the total number of apples. This will help maintain clarity and prevent confusion during calculations.\n",
      "\n",
      "3. **Breaking Down the Problem**  \n",
      "   - List the events in chronological order:\n",
      "     1. Initial count of oranges: 15\n",
      "     2. Giving 4 oranges to his brother\n",
      "     3. Trading 3 oranges for 6 apples\n",
      "     4. Discarding 2 spoiled oranges\n",
      "     5. Buying 12 more oranges and 5 more apples\n",
      "     6. Giving 2 apples to a friend\n",
      "\n",
      "4. **Critical Thinking**  \n",
      "   - For each transaction, ask questions such as:\n",
      "     - Is the initial count accurate?\n",
      "     - Are the transactions correctly represented?\n",
      "     - Have I accounted for all changes in the count of fruits?\n",
      "\n",
      "5. **Step-by-Step Outline**  \n",
      "   - Write down each action Michael takes, along with the resulting counts:\n",
      "     - Start with 15 oranges.\n",
      "     - After giving away 4 oranges: (15 - 4 = 11 oranges)\n",
      "     - After trading 3 oranges for 6 apples: (11 - 3 = 8 oranges, 0 + 6 = 6 apples)\n",
      "     - After discarding 2 spoiled oranges: (8 - 2 = 6 oranges)\n",
      "     - After buying 12 more oranges and 5 more apples: (6 + 12 = 18 oranges, 6 + 5 = 11 apples)\n",
      "     - After giving 2 apples to a friend: (18 oranges, 11 - 2 = 9 apples)\n",
      "\n",
      "6. **Step-by-Step Plan with Notation**  \n",
      "   - Create a clear list of calculations with notation:\n",
      "     - Let O = number of oranges, A = number of apples.\n",
      "     - Initial: O = 15, A = 0\n",
      "     - After giving to brother: O = O - 4\n",
      "     - After trading: O = O - 3, A = A + 6\n",
      "     - After discarding: O = O - 2\n",
      "     - After buying: O = O + 12, A = A + 5\n",
      "     - After giving to friend: A = A - 2\n",
      "\n",
      "By following this structured approach, the problem can be tackled systematically, ensuring clarity and accuracy in the calculations.\n",
      "\n",
      "\n",
      "Step create_reasoning_structure produced event ReasoningStructureEvent\n",
      "Running step get_final_result\n",
      "\n",
      "\n",
      "Reasoning: Let's solve the task step by step using the actionable reasoning structure provided:\n",
      "\n",
      "### Step-by-Step Solution\n",
      "\n",
      "1. **Initial Count of Oranges and Apples**  \n",
      "   - Initial count of oranges: \\( O = 15 \\)  \n",
      "   - Initial count of apples: \\( A = 0 \\)\n",
      "\n",
      "2. **Giving 4 Oranges to His Brother**  \n",
      "   - New count of oranges:  \n",
      "     \\[\n",
      "     O = O - 4 = 15 - 4 = 11\n",
      "     \\]\n",
      "\n",
      "3. **Trading 3 Oranges for 6 Apples**  \n",
      "   - New count of oranges and apples:  \n",
      "     \\[\n",
      "     O = O - 3 = 11 - 3 = 8 \\quad \\text{(oranges)}  \n",
      "     \\]\n",
      "     \\[\n",
      "     A = A + 6 = 0 + 6 = 6 \\quad \\text{(apples)}\n",
      "     \\]\n",
      "\n",
      "4. **Discarding 2 Spoiled Oranges**  \n",
      "   - New count of oranges:  \n",
      "     \\[\n",
      "     O = O - 2 = 8 - 2 = 6\n",
      "     \\]\n",
      "\n",
      "5. **Buying 12 More Oranges and 5 More Apples**  \n",
      "   - New count of oranges and apples:  \n",
      "     \\[\n",
      "     O = O + 12 = 6 + 12 = 18 \\quad \\text{(oranges)}  \n",
      "     \\]\n",
      "     \\[\n",
      "     A = A + 5 = 6 + 5 = 11 \\quad \\text{(apples)}\n",
      "     \\]\n",
      "\n",
      "6. **Giving 2 Apples to a Friend**  \n",
      "   - New count of apples:  \n",
      "     \\[\n",
      "     A = A - 2 = 11 - 2 = 9\n",
      "     \\]\n",
      "\n",
      "### Final Counts\n",
      "- Total number of oranges: \\( O = 18 \\)\n",
      "- Total number of apples: \\( A = 9 \\)\n",
      "\n",
      "### Final Answer\n",
      "Michael has **18 oranges** and **9 apples**.\n",
      "\n",
      "\n",
      "Step get_final_result produced event StopEvent\n"
     ]
    }
   ],
   "source": [
    "task = \"\"\"Michael has 15 oranges. He gives 4 oranges to his brother and trades 3 oranges for 6 apples with his neighbor. \n",
    "Later in the day, he realizes some of his oranges are spoiled, so he discards 2 of them. Then, Michael goes to the market and buys 12 more oranges and 5 more apples.\n",
    "If Michael decides to give 2 apples to his friend, how many oranges and apples does Michael have now?\"\"\"\n",
    "\n",
    "result = await app.run(task=task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "response, history = result.split(\" ||History||: \")[0], json.loads(result.split(\" ||History||: \")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Let's solve the task step by step using the actionable reasoning structure provided:\n",
       "\n",
       "### Step-by-Step Solution\n",
       "\n",
       "1. **Initial Count of Oranges and Apples**  \n",
       "   - Initial count of oranges: \\( O = 15 \\)  \n",
       "   - Initial count of apples: \\( A = 0 \\)\n",
       "\n",
       "2. **Giving 4 Oranges to His Brother**  \n",
       "   - New count of oranges:  \n",
       "     \\[\n",
       "     O = O - 4 = 15 - 4 = 11\n",
       "     \\]\n",
       "\n",
       "3. **Trading 3 Oranges for 6 Apples**  \n",
       "   - New count of oranges and apples:  \n",
       "     \\[\n",
       "     O = O - 3 = 11 - 3 = 8 \\quad \\text{(oranges)}  \n",
       "     \\]\n",
       "     \\[\n",
       "     A = A + 6 = 0 + 6 = 6 \\quad \\text{(apples)}\n",
       "     \\]\n",
       "\n",
       "4. **Discarding 2 Spoiled Oranges**  \n",
       "   - New count of oranges:  \n",
       "     \\[\n",
       "     O = O - 2 = 8 - 2 = 6\n",
       "     \\]\n",
       "\n",
       "5. **Buying 12 More Oranges and 5 More Apples**  \n",
       "   - New count of oranges and apples:  \n",
       "     \\[\n",
       "     O = O + 12 = 6 + 12 = 18 \\quad \\text{(oranges)}  \n",
       "     \\]\n",
       "     \\[\n",
       "     A = A + 5 = 6 + 5 = 11 \\quad \\text{(apples)}\n",
       "     \\]\n",
       "\n",
       "6. **Giving 2 Apples to a Friend**  \n",
       "   - New count of apples:  \n",
       "     \\[\n",
       "     A = A - 2 = 11 - 2 = 9\n",
       "     \\]\n",
       "\n",
       "### Final Counts\n",
       "- Total number of oranges: \\( O = 18 \\)\n",
       "- Total number of apples: \\( A = 9 \\)\n",
       "\n",
       "### Final Answer\n",
       "Michael has **18 oranges** and **9 apples**."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llamaindex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4fb762c9777d81b920bdc4f2aaae00fd18dcefdd6f60d8272d61e705ce6e5d33"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
